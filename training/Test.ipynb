{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Test.ipynb","provenance":[],"authorship_tag":"ABX9TyPpXVddB0aOizShqVK3btuL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"WESqSfSPnyjc","colab_type":"code","outputId":"44f1e1f2-7a1f-4614-a71e-b79c60057df3","executionInfo":{"status":"ok","timestamp":1588682762236,"user_tz":-120,"elapsed":34219,"user":{"displayName":"ENRICO SAMMARCO","photoUrl":"","userId":"10417850865031477899"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount = True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hBRVB1xLoIb6","colab_type":"code","colab":{}},"source":["!cp /content/drive/My\\ Drive/FaceMask/face_mask_test.txt /content/\n","!cp /content/drive/My\\ Drive/FaceMask/face_mask_train.txt /content/\n","!unzip -q /content/drive/My\\ Drive/FaceMask/FaceMaskDataset.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rUbEghVzoI80","colab_type":"code","outputId":"10226758-c55f-4e0c-e0a8-e731ea8d017d","executionInfo":{"status":"ok","timestamp":1588682787310,"user_tz":-120,"elapsed":59268,"user":{"displayName":"ENRICO SAMMARCO","photoUrl":"","userId":"10417850865031477899"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["!git clone https://github.com/qqwweee/keras-yolo3.git\n","\n","import os\n","for i in os.listdir(\"keras-yolo3/\"):\n","  os.system(\"mv keras-yolo3/\"+i+\" /content/\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Cloning into 'keras-yolo3'...\n","remote: Enumerating objects: 144, done.\u001b[K\n","remote: Total 144 (delta 0), reused 0 (delta 0), pack-reused 144\u001b[K\n","Receiving objects: 100% (144/144), 151.07 KiB | 626.00 KiB/s, done.\n","Resolving deltas: 100% (65/65), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_k1THVeDoLVH","colab_type":"code","outputId":"a8ffe3bb-69fc-4038-977e-7c59818fd179","executionInfo":{"status":"ok","timestamp":1588682803648,"user_tz":-120,"elapsed":75594,"user":{"displayName":"ENRICO SAMMARCO","photoUrl":"","userId":"10417850865031477899"}},"colab":{"base_uri":"https://localhost:8080/","height":292}},"source":["!pip install keras==2.1.5\n","\n","%tensorflow_version 1.x\n","import tensorflow as tf\n","import sys\n","import argparse\n","from yolo import YOLO\n","from PIL import Image\n","import os\n","from yolo3.model import *\n","from yolo3.utils import *\n","tf.version.VERSION"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting keras==2.1.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/65/e4aff762b8696ec0626a6654b1e73b396fcc8b7cc6b98d78a1bc53b85b48/Keras-2.1.5-py2.py3-none-any.whl (334kB)\n","\r\u001b[K     |█                               | 10kB 15.1MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 4.5MB/s eta 0:00:01\r\u001b[K     |███                             | 30kB 6.3MB/s eta 0:00:01\r\u001b[K     |████                            | 40kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 51kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 61kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 71kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 81kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 92kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 102kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 112kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 122kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 133kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 143kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 153kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 163kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 174kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 184kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 194kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 204kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 215kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 225kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 235kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 245kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 256kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 266kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 276kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 286kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 296kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 307kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 317kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 327kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 337kB 6.4MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.18.3)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.12.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (3.13)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.4.1)\n","Installing collected packages: keras\n","  Found existing installation: Keras 2.3.1\n","    Uninstalling Keras-2.3.1:\n","      Successfully uninstalled Keras-2.3.1\n","Successfully installed keras-2.1.5\n","TensorFlow 1.x selected.\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["'1.15.2'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"QztovmHYoTe_","colab_type":"code","colab":{}},"source":["from IPython.display import display\n","\n","def detecting_image(detector, image):\n","  punti = []\n","  plates = []\n","  if detector.model_image_size != (None, None):\n","      assert detector.model_image_size[0]%32 == 0, 'Multiples of 32 required'\n","      assert detector.model_image_size[1]%32 == 0, 'Multiples of 32 required'\n","      boxed_image = letterbox_image(image, tuple(reversed(detector.model_image_size)))\n","  else:\n","      new_image_size = (image.width - (image.width % 32),\n","                        image.height - (image.height % 32))\n","      boxed_image = letterbox_image(image, new_image_size)\n","  image_data = np.array(boxed_image, dtype='float32')\n","\n","  # print(image_data.shape)\n","  image_data /= 255.\n","  image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n","\n","  out_boxes, out_scores, out_classes = detector.sess.run(\n","      [detector.boxes, detector.scores, detector.classes],\n","      feed_dict={\n","          detector.yolo_model.input: image_data,\n","          detector.input_image_shape: [image.size[1], image.size[0]],\n","          K.learning_phase(): 0\n","      })\n","\n","  # print('Found {} boxes for {}'.format(len(out_boxes), 'img'))\n","\n","  font = ImageFont.truetype(font='font/FiraMono-Medium.otf',\n","              size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n","  thickness = (image.size[0] + image.size[1]) // 300\n","\n","  for i, c in reversed(list(enumerate(out_classes))):\n","      predicted_class = detector.class_names[c]\n","      box = out_boxes[i]\n","      score = out_scores[i]\n","\n","      label = '{} {:.2f}'.format(predicted_class, score)\n","      draw = ImageDraw.Draw(image)\n","      label_size = draw.textsize(label, font)\n","      top, left, bottom, right = box\n","\n","      top = max(0, np.floor(top + 0.5).astype('int32'))\n","      left = max(0, np.floor(left + 0.5).astype('int32'))\n","      bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n","      right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n","      #print(label, (left, top), (right, bottom))\n","\n","      punti.append([(left,top),(right, bottom)])\n","      plates.append([left,top,right-left,bottom-top])\n","  \n","\n","  return punti,plates,image"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9VsYf2USoUBv","colab_type":"code","colab":{}},"source":["f = open(\"classes.txt\",\"w\")\n","f.write(\"face\\n\")\n","f.write(\"face_mask\")\n","f.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tM87axiLobXn","colab_type":"code","colab":{}},"source":["%tensorflow_version 1.x\n","import cv2\n","import os\n","from PIL import Image, ImageFont, ImageDraw\n","import numpy as np\n","from matplotlib.colors import rgb_to_hsv, hsv_to_rgb\n","from IPython.display import display\n","\n","def bb_intersection_over_union(boxA, boxB):\n","    xA = max(boxA[0], boxB[0])\n","    yA = max(boxA[1], boxB[1])\n","    xB = min(boxA[2], boxB[2])\n","    yB = min(boxA[3], boxB[3])\n","    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n","    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n","    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n","    iou = interArea / float(boxAArea + boxBArea - interArea)\n","    return iou\n","\n","def classification(detector,path_img):\n","\n","    image = Image.open(path_img)\n","    w_img,h_img = image.size\n","    punti, plates, iii = detecting_image(detector,image)\n","\n","    real_plates = {}\n","    # for (x, y, w, h) in plates:\n","    #     real_plates[(x, y, w, h)] = True\n","\n","    # for (x, y, w, h) in plates:\n","    #     for (x2, y2, w2, h2) in real_plates.keys():\n","    #         if real_plates[(x2, y2, w2, h2)] == False:\n","    #             continue\n","    #     iou = bb_intersection_over_union([x, y, x + w, y + h], [x2, y2, w2 + x2, h2 + y2])\n","    #     if (iou > 0.1 and iou != 1.0):\n","    #         if (w * h) > (w2 * h2):\n","    #             real_plates[(x2, y2, w2, h2)] = False\n","    #         else:\n","    #             real_plates[(x, y, w, h)] = False\n","      \n","      \n","    return punti, real_plates,iii"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vWUCrB4iwpzZ","colab_type":"code","outputId":"f2f3d16c-8242-4711-ca92-c483aaaf92f5","executionInfo":{"status":"ok","timestamp":1588682807561,"user_tz":-120,"elapsed":79463,"user":{"displayName":"ENRICO SAMMARCO","photoUrl":"","userId":"10417850865031477899"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["!git clone https://github.com/swdev1202/keras-yolo3-facedetection.git\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Cloning into 'keras-yolo3-facedetection'...\n","remote: Enumerating objects: 216, done.\u001b[K\n","remote: Total 216 (delta 0), reused 0 (delta 0), pack-reused 216\u001b[K\n","Receiving objects: 100% (216/216), 5.75 MiB | 7.84 MiB/s, done.\n","Resolving deltas: 100% (107/107), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k76Py4BBo406","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1d6hKaTHCh7n78_GYi5FSSU4Me9nICMqd"},"outputId":"819ded10-132c-44d5-f25a-37fa7b153d1b","executionInfo":{"status":"ok","timestamp":1588682873944,"user_tz":-120,"elapsed":145836,"user":{"displayName":"ENRICO SAMMARCO","photoUrl":"","userId":"10417850865031477899"}}},"source":["from IPython.display import display\n","from random import randint\n","from PIL import Image, ImageDraw\n","import progressbar\n","\n","test_img = \"val/\"\n","model_path = \"/content/drive/My Drive/FaceMask/YoloFaceDataAug/ep007-loss18.117-val_loss16.969.h5\"\n","\n","\n","f = open(\"FACE.txt\",\"w\")\n","f.write(\"face\")\n","f.close()\n","\n","arg = {\n","      \"model_path\": model_path,\n","      #\"anchors_path\": 'model_data/yolo_anchors.txt', #YOLOV3\n","      \"anchors_path\": '/content/keras-yolo3-facedetection/model_data/wider_anchors.txt',  #YOLOFACE\n","      \"classes_path\": 'classes.txt',\n","      #\"classes_path\": 'FACE.txt',\n","      \"score\" : 0.3,\n","      \"iou\" : 0.45,\n","      #\"model_image_size\" : (416, 416), #YOLOV3\n","      \"model_image_size\" : (608,608),  #YOLOFACE\n","      \"gpu_num\" : 1,\n","  }\n","detector = YOLO(**arg)\n","\n","\n","j = 0\n","for i in os.listdir(test_img):\n","  if \"jpg\" in i :\n","    img_path = test_img+i\n","    image = Image.open(img_path)\n","    iii = detector.detect_image(image)\n","    iii = image.resize( (int(iii.size[0]/4) , int(iii.size[1]/4)) )\n","    display(iii)\n","    #bar.update(j)\n","    j = j+1\n","    if j==50:\n","      break\n","\n","#bar = progressbar.ProgressBar(max_value=len(os.listdir(test_img))/2)\n","# j = 0\n","# for i in os.listdir(test_img):\n","#   if \"jpg\" in i :\n","#     img_path = test_img+i\n","\n","#     punti, real_plates,iii = classification(detector, img_path)\n","#     draw = ImageDraw.Draw(iii)\n","#     for i in punti:\n","#       draw.rectangle(i)\n","#     display(iii)\n","#     print(punti)\n","#     #bar.update(j)\n","#     j = j+1\n","#     if j==10:\n","#       break\n","\n","  \n"],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"wbHW2Vmmn4SQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"10SjeVvl7O-UsEx8dznKp3cZ6gU8BkYxt"},"outputId":"904c649f-ee10-465a-c72e-6f72ab627c6c","executionInfo":{"status":"ok","timestamp":1588682907986,"user_tz":-120,"elapsed":32946,"user":{"displayName":"ENRICO SAMMARCO","photoUrl":"","userId":"10417850865031477899"}}},"source":["from IPython.display import display\n","from random import randint\n","from PIL import Image, ImageDraw\n","import progressbar\n","\n","test_img = \"val/\"\n","model_path = \"/content/drive/My Drive/FaceMask/TinyYoloDataAug/ep029-loss11.815-val_loss11.278.h5\"\n","\n","arg = {\n","      \"model_path\": model_path,\n","      \"anchors_path\": '/content/model_data/tiny_yolo_anchors.txt', #YOLOV3\n","      \"classes_path\": 'classes.txt',\n","      \"score\" : 0.3,\n","      \"iou\" : 0.45,\n","      \"model_image_size\" : (416, 416), #YOLOV3\n","      \"gpu_num\" : 1,\n","  }\n","detector = YOLO(**arg)\n","\n","\n","j = 0\n","for i in os.listdir(test_img):\n","  if \"jpg\" in i :\n","    img_path = test_img+i\n","    image = Image.open(img_path)\n","    iii = detector.detect_image(image)\n","    iii = image.resize( (int(iii.size[0]/4) , int(iii.size[1]/4)) )\n","    display(iii)\n","    #bar.update(j)\n","    j = j+1\n","    if j==50:\n","      break"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}