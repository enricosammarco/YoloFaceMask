{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TestPerformance.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP1qCqqoC88PLCpzVpYAB3R"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"WESqSfSPnyjc","colab_type":"code","outputId":"c9ca5600-9df1-4f66-dd54-33d7e56ea070","executionInfo":{"status":"ok","timestamp":1590275168514,"user_tz":-120,"elapsed":25985,"user":{"displayName":"ENRICO SAMMARCO","photoUrl":"","userId":"10417850865031477899"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount = True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hBRVB1xLoIb6","colab_type":"code","outputId":"17bac4a0-9f56-4db3-d93a-2cad1297d738","executionInfo":{"status":"ok","timestamp":1588865983015,"user_tz":-120,"elapsed":225451,"user":{"displayName":"ENRICO SAMMARCO","photoUrl":"","userId":"10417850865031477899"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!cp /content/drive/My\\ Drive/FaceMask/face_mask_test_corrette.txt /content/\n","!cp /content/drive/My\\ Drive/FaceMask/face_mask_train_corrette.txt /content/\n","!unzip -q /content/drive/My\\ Drive/FaceMask/FaceMaskDataset.zip"],"execution_count":0,"outputs":[{"output_type":"stream","text":["replace train/test_00000127.xml? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rUbEghVzoI80","colab_type":"code","outputId":"294871e0-25e4-454c-e5e4-bcdafd1b80d5","executionInfo":{"status":"ok","timestamp":1588865986913,"user_tz":-120,"elapsed":229333,"user":{"displayName":"ENRICO SAMMARCO","photoUrl":"","userId":"10417850865031477899"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["!git clone https://github.com/qqwweee/keras-yolo3.git\n","\n","import os\n","for i in os.listdir(\"keras-yolo3/\"):\n","  os.system(\"mv keras-yolo3/\"+i+\" /content/\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Cloning into 'keras-yolo3'...\n","remote: Enumerating objects: 144, done.\u001b[K\n","Receiving objects:   0% (1/144)   \rReceiving objects:   1% (2/144)   \rReceiving objects:   2% (3/144)   \rReceiving objects:   3% (5/144)   \rReceiving objects:   4% (6/144)   \rReceiving objects:   5% (8/144)   \rReceiving objects:   6% (9/144)   \rReceiving objects:   7% (11/144)   \rReceiving objects:   8% (12/144)   \rReceiving objects:   9% (13/144)   \rReceiving objects:  10% (15/144)   \rReceiving objects:  11% (16/144)   \rReceiving objects:  12% (18/144)   \rReceiving objects:  13% (19/144)   \rReceiving objects:  14% (21/144)   \rReceiving objects:  15% (22/144)   \rReceiving objects:  16% (24/144)   \rReceiving objects:  17% (25/144)   \rReceiving objects:  18% (26/144)   \rReceiving objects:  19% (28/144)   \rReceiving objects:  20% (29/144)   \rReceiving objects:  21% (31/144)   \rReceiving objects:  22% (32/144)   \rReceiving objects:  23% (34/144)   \rReceiving objects:  24% (35/144)   \rReceiving objects:  25% (36/144)   \rReceiving objects:  26% (38/144)   \rReceiving objects:  27% (39/144)   \rReceiving objects:  28% (41/144)   \rReceiving objects:  29% (42/144)   \rReceiving objects:  30% (44/144)   \rReceiving objects:  31% (45/144)   \rReceiving objects:  32% (47/144)   \rReceiving objects:  33% (48/144)   \rReceiving objects:  34% (49/144)   \rReceiving objects:  35% (51/144)   \rReceiving objects:  36% (52/144)   \rReceiving objects:  37% (54/144)   \rReceiving objects:  38% (55/144)   \rReceiving objects:  39% (57/144)   \rReceiving objects:  40% (58/144)   \rReceiving objects:  41% (60/144)   \rReceiving objects:  42% (61/144)   \rReceiving objects:  43% (62/144)   \rReceiving objects:  44% (64/144)   \rReceiving objects:  45% (65/144)   \rReceiving objects:  46% (67/144)   \rReceiving objects:  47% (68/144)   \rReceiving objects:  48% (70/144)   \rReceiving objects:  49% (71/144)   \rReceiving objects:  50% (72/144)   \rReceiving objects:  51% (74/144)   \rReceiving objects:  52% (75/144)   \rReceiving objects:  53% (77/144)   \rReceiving objects:  54% (78/144)   \rReceiving objects:  55% (80/144)   \rReceiving objects:  56% (81/144)   \rReceiving objects:  57% (83/144)   \rReceiving objects:  58% (84/144)   \rReceiving objects:  59% (85/144)   \rReceiving objects:  60% (87/144)   \rReceiving objects:  61% (88/144)   \rReceiving objects:  62% (90/144)   \rReceiving objects:  63% (91/144)   \rReceiving objects:  64% (93/144)   \rReceiving objects:  65% (94/144)   \rremote: Total 144 (delta 0), reused 0 (delta 0), pack-reused 144\u001b[K\n","Receiving objects:  66% (96/144)   \rReceiving objects:  67% (97/144)   \rReceiving objects:  68% (98/144)   \rReceiving objects:  69% (100/144)   \rReceiving objects:  70% (101/144)   \rReceiving objects:  71% (103/144)   \rReceiving objects:  72% (104/144)   \rReceiving objects:  73% (106/144)   \rReceiving objects:  74% (107/144)   \rReceiving objects:  75% (108/144)   \rReceiving objects:  76% (110/144)   \rReceiving objects:  77% (111/144)   \rReceiving objects:  78% (113/144)   \rReceiving objects:  79% (114/144)   \rReceiving objects:  80% (116/144)   \rReceiving objects:  81% (117/144)   \rReceiving objects:  82% (119/144)   \rReceiving objects:  83% (120/144)   \rReceiving objects:  84% (121/144)   \rReceiving objects:  85% (123/144)   \rReceiving objects:  86% (124/144)   \rReceiving objects:  87% (126/144)   \rReceiving objects:  88% (127/144)   \rReceiving objects:  89% (129/144)   \rReceiving objects:  90% (130/144)   \rReceiving objects:  91% (132/144)   \rReceiving objects:  92% (133/144)   \rReceiving objects:  93% (134/144)   \rReceiving objects:  94% (136/144)   \rReceiving objects:  95% (137/144)   \rReceiving objects:  96% (139/144)   \rReceiving objects:  97% (140/144)   \rReceiving objects:  98% (142/144)   \rReceiving objects:  99% (143/144)   \rReceiving objects: 100% (144/144)   \rReceiving objects: 100% (144/144), 151.07 KiB | 585.00 KiB/s, done.\n","Resolving deltas:   0% (0/65)   \rResolving deltas:   3% (2/65)   \rResolving deltas:   6% (4/65)   \rResolving deltas:   9% (6/65)   \rResolving deltas:  15% (10/65)   \rResolving deltas:  16% (11/65)   \rResolving deltas:  18% (12/65)   \rResolving deltas:  20% (13/65)   \rResolving deltas:  24% (16/65)   \rResolving deltas:  35% (23/65)   \rResolving deltas:  50% (33/65)   \rResolving deltas:  64% (42/65)   \rResolving deltas:  66% (43/65)   \rResolving deltas:  67% (44/65)   \rResolving deltas:  78% (51/65)   \rResolving deltas:  80% (52/65)   \rResolving deltas:  86% (56/65)   \rResolving deltas:  89% (58/65)   \rResolving deltas:  93% (61/65)   \rResolving deltas:  98% (64/65)   \rResolving deltas: 100% (65/65)   \rResolving deltas: 100% (65/65), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_k1THVeDoLVH","colab_type":"code","outputId":"2b895261-5adb-48a7-90d0-6a60e8820288","executionInfo":{"status":"ok","timestamp":1588865990767,"user_tz":-120,"elapsed":233174,"user":{"displayName":"ENRICO SAMMARCO","photoUrl":"","userId":"10417850865031477899"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["!pip install keras==2.1.5\n","\n","%tensorflow_version 1.x\n","import tensorflow as tf\n","import sys\n","import argparse\n","from yolo import YOLO\n","from PIL import Image\n","import os\n","from yolo3.model import *\n","from yolo3.utils import *\n","tf.version.VERSION"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: keras==2.1.5 in /usr/local/lib/python3.6/dist-packages (2.1.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (3.13)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.18.3)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.12.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.4.1)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["'1.15.2'"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"QztovmHYoTe_","colab_type":"code","colab":{}},"source":["from IPython.display import display\n","\n","def detecting_image(detector, image):\n","    bb = []\n","    classi = []\n","    if detector.model_image_size != (None, None):\n","        assert detector.model_image_size[0] % 32 == 0, 'Multiples of 32 required'\n","        assert detector.model_image_size[1] % 32 == 0, 'Multiples of 32 required'\n","        boxed_image = letterbox_image(image, tuple(reversed(detector.model_image_size)))\n","    else:\n","        new_image_size = (image.width - (image.width % 32),\n","                          image.height - (image.height % 32))\n","        boxed_image = letterbox_image(image, new_image_size)\n","    image_data = np.array(boxed_image, dtype='float32')\n","\n","    # print(image_data.shape)\n","    image_data /= 255.\n","    image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n","\n","    out_boxes, out_scores, out_classes = detector.sess.run(\n","        [detector.boxes, detector.scores, detector.classes],\n","        feed_dict={\n","            detector.yolo_model.input: image_data,\n","            detector.input_image_shape: [image.size[1], image.size[0]],\n","            K.learning_phase(): 0\n","        })\n","\n","    # print('Found {} boxes for {}'.format(len(out_boxes), 'img'))\n","\n","    for i, c in reversed(list(enumerate(out_classes))):\n","        predicted_class = detector.class_names[c]\n","        box = out_boxes[i]\n","        score = out_scores[i]\n","\n","        top, left, bottom, right = box\n","\n","        top = max(0, np.floor(top + 0.5).astype('int32'))\n","        left = max(0, np.floor(left + 0.5).astype('int32'))\n","        bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n","        right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n","        # print(label, (left, top), (right, bottom))\n","\n","        bb.append([left, top, right, bottom])\n","        if predicted_class == \"face\":\n","            classi.append(0)\n","        else:\n","            classi.append(1)\n","\n","    bb_final = []\n","    classes_final = []\n","    for index in range(0,len(classi)):\n","        if classi[index] == 1:\n","            bb_final.append(bb[index])\n","            classes_final.append(classi[index])\n","\n","    bb_0 = []\n","    for index in range(0, len(classi)):\n","        if classi[index] == 0:\n","            flag = True\n","            for mask in bb_final:\n","                iou = bb_intersection_over_union(mask,bb[index])\n","                if iou>0.5:\n","                    flag = False\n","                    break\n","            if flag:\n","                bb_0.append(bb[index])\n","    for i in bb_0:\n","        bb_final.append(i)\n","        classes_final.append(0)\n","\n","    return bb_final, classes_final"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9VsYf2USoUBv","colab_type":"code","colab":{}},"source":["f = open(\"classes.txt\",\"w\")\n","f.write(\"face\\n\")\n","f.write(\"face_mask\")\n","f.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tM87axiLobXn","colab_type":"code","colab":{}},"source":["%tensorflow_version 1.x\n","import cv2\n","import os\n","from PIL import Image, ImageFont, ImageDraw\n","import numpy as np\n","from matplotlib.colors import rgb_to_hsv, hsv_to_rgb\n","from IPython.display import display\n","\n","def bb_intersection_over_union(boxA, boxB):\n","    xA = max(boxA[0], boxB[0])\n","    yA = max(boxA[1], boxB[1])\n","    xB = min(boxA[2], boxB[2])\n","    yB = min(boxA[3], boxB[3])\n","    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n","    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n","    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n","    iou = interArea / float(boxAArea + boxBArea - interArea)\n","    return iou\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vWUCrB4iwpzZ","colab_type":"code","outputId":"5be7623e-3cbc-42b6-ea2b-b9ffa20e8484","executionInfo":{"status":"ok","timestamp":1588865994368,"user_tz":-120,"elapsed":236736,"user":{"displayName":"ENRICO SAMMARCO","photoUrl":"","userId":"10417850865031477899"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!git clone https://github.com/swdev1202/keras-yolo3-facedetection.git\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["fatal: destination path 'keras-yolo3-facedetection' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mzS2jIaI6Hs9","colab_type":"code","colab":{}},"source":["def compute_performance(predinput, trueinput, pred_classes, true_classes):\n","  pred = []\n","  true = []\n","  for x in range(0,len(predinput)):\n","    pred.append({'p':predinput[x], 'matched':False, 'class':pred_classes[x]})\n","  for x in range(0,len(trueinput)):\n","    true.append({'p':trueinput[x], 'matched':False, 'class':true_classes[x]})\n","\n","  ce = 0\n","  tp = 0\n","  fp = 0\n","  fn = 0\n","\n","  for p in pred:\n","    for t in true:\n","      if not t['matched'] and not p['matched']:\n","        try:\n","          iou = bb_intersection_over_union(p['p'], t['p'])\n","                    \n","\n","          if iou > 0.5:\n","            t['matched'] = True\n","            p['matched'] = True\n","            if p['class'] == t['class']:\n","              tp += 1\n","            else:\n","              ce += 1\n","        except:\n","          for t in true:\n","            if not t['matched']:\n","              fn += 1\n","          print(\"Error computing performance\")\n","                    \n","                   \n","    if not p['matched']:\n","      fp +=1\n","  for t in true:\n","    if not t['matched']:\n","      fn += 1\n","  \n","  return (tp,ce,fp,fn)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k76Py4BBo406","colab_type":"code","outputId":"6d4082d4-59a1-485b-b6e7-c364352700ca","executionInfo":{"status":"ok","timestamp":1588866791434,"user_tz":-120,"elapsed":373282,"user":{"displayName":"ENRICO SAMMARCO","photoUrl":"","userId":"10417850865031477899"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["#############################\n","\n","  #  yolo face\n","\n","##############################\n","\n","from IPython.display import display\n","from random import randint\n","from PIL import Image, ImageDraw\n","import progressbar\n","\n","\n","model_path = \"/content/drive/My Drive/FaceMask/YoloFaceDataAug/ep068-loss9.167-val_loss9.443.h5\"\n","txt = open(\"face_mask_test_corrette.txt\",\"r\")\n","label = txt.readlines()\n","label = label[:len(label)-1]\n","txt.close()\n","\n","tpTot = 0\n","ceTot = 0\n","fpTot = 0\n","fnTot = 0\n","totBB = 0\n","\n","arg = {\n","      \"model_path\": model_path,\n","      \"anchors_path\": '/content/keras-yolo3-facedetection/model_data/wider_anchors.txt',  #YOLOFACE\n","      \"classes_path\": 'classes.txt',\n","      \"score\" : 0.3,\n","      \"iou\" : 0.45,\n","      \"model_image_size\" : (608,608),  #YOLOFACE\n","      \"gpu_num\" : 1,\n","  }\n","detector = YOLO(**arg)\n","\n","bar = progressbar.ProgressBar(max_value=len(label))\n","cont = 0\n","\n","for i in label:\n","  s = i.split(\" \")\n","  true = []\n","  true_classes = []\n","  image = Image.open(s[0])\n","  for j in range(1,len(s)):\n","    punti = s[j].split(\",\")\n","    try:\n","      true.append([int(punti[0]),int(punti[1]),int(punti[2]),int(punti[3]) ])\n","      true_classes.append(int(punti[4]))\n","    except:\n","      print(i)\n","      for punto in punti:\n","        print(punto)\n","  \n","  predicted,pred_classes = detecting_image(detector, image)\n","  tp,ce,fp,fn = compute_performance(predicted, true, pred_classes, true_classes)\n","\n","  tpTot += tp\n","  ceTot += ce\n","  fpTot += fp\n","  fnTot += fn\n","\n","  bar.update(cont)\n","  cont = cont+1\n","  totBB +=len(true)\n","  # print(\"Confronto immagine numero : \"+str(cont)+\" BB presenti:\"+str(len(true))+\" BB trovati: \"+str(len(predicted)))\n","  # print(pred_classes)\n","\n","\n","print(\"BB true totali: \"+str(totBB))\n","print(\"True positive: \"+str(tpTot))\n","print(\"Classification error: \"+str(ceTot))\n","print(\"False positive: \"+str(fpTot))\n","print(\"False negative: \"+str(fnTot))\n","\n","R = tpTot/totBB\n","P = tpTot/(tpTot+fpTot)\n","A = tpTot/(tpTot+ceTot)\n","\n","print(\"Recall: \"+str(R))\n","print(\"Precision: \"+str(P))\n","print(\"Accuracy: \"+str(A))\n","  \n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/FaceMask/YoloFaceDataAug/ep068-loss9.167-val_loss9.443.h5 model, anchors, and classes loaded.\n"],"name":"stdout"},{"output_type":"stream","text":[" 99% (1837 of 1838) |################### | Elapsed Time: 0:05:44 ETA:   0:00:00"],"name":"stderr"},{"output_type":"stream","text":["BB true totali: 3061\n","True positive: 2829\n","Classification error: 93\n","False positive: 118\n","False negative: 139\n","Recall: 0.9242077752368507\n","Precision: 0.9599592806243638\n","Accuracy: 0.9681724845995893\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n5Jd4gNbDptf","colab_type":"code","outputId":"06c8424a-bddf-49e4-d79b-8204f8af4ed5","executionInfo":{"status":"ok","timestamp":1588867041800,"user_tz":-120,"elapsed":619802,"user":{"displayName":"ENRICO SAMMARCO","photoUrl":"","userId":"10417850865031477899"}},"colab":{"base_uri":"https://localhost:8080/","height":190}},"source":["\n","####################################\n","\n","    # yolo v3 doppio training\n","\n","####################################\n","\n","from IPython.display import display\n","from random import randint\n","from PIL import Image, ImageDraw\n","import progressbar\n","\n","\n","model_path = \"/content/drive/My Drive/FaceMask/DarknetYoloNoDataAug/trainingcompleto/ep080-loss8.454-val_loss8.272.h5\"\n","txt = open(\"face_mask_test_corrette.txt\",\"r\")\n","label = txt.readlines()\n","label = label[:len(label)-1]\n","txt.close()\n","\n","tpTot = 0\n","ceTot = 0\n","fpTot = 0\n","fnTot = 0\n","totBB = 0\n","\n","arg = {\n","      \"model_path\": model_path,\n","      \"anchors_path\": 'model_data/yolo_anchors.txt', #YOLOV3\n","      \"classes_path\": 'classes.txt',\n","      \"score\" : 0.3,\n","      \"iou\" : 0.45,\n","      \"model_image_size\" : (416, 416), #YOLOV3\n","      \"gpu_num\" : 1,\n","  }\n","detector = YOLO(**arg)\n","\n","bar = progressbar.ProgressBar(max_value=len(label))\n","cont = 0\n","\n","for i in label:\n","  s = i.split(\" \")\n","  true = []\n","  true_classes = []\n","  image = Image.open(s[0])\n","  for j in range(1,len(s)):\n","    punti = s[j].split(\",\")\n","    try:\n","      true.append([int(punti[0]),int(punti[1]),int(punti[2]),int(punti[3]) ])\n","      true_classes.append(int(punti[4]))\n","    except:\n","      print(i)\n","      for punto in punti:\n","        print(punto)\n","  \n","  predicted,pred_classes = detecting_image(detector, image)\n","  tp,ce,fp,fn = compute_performance(predicted, true, pred_classes, true_classes)\n","\n","  tpTot += tp\n","  ceTot += ce\n","  fpTot += fp\n","  fnTot += fn\n","\n","  bar.update(cont)\n","  cont = cont+1\n","  totBB +=len(true)\n","  # print(\"Confronto immagine numero : \"+str(cont)+\" BB presenti:\"+str(len(true))+\" BB trovati: \"+str(len(predicted)))\n","  # print(pred_classes)\n","\n","\n","print(\"BB true totali: \"+str(totBB))\n","print(\"True positive: \"+str(tpTot))\n","print(\"Classification error: \"+str(ceTot))\n","print(\"False positive: \"+str(fpTot))\n","print(\"False negative: \"+str(fnTot))\n","\n","R = tpTot/totBB\n","P = tpTot/(tpTot+fpTot)\n","A = tpTot/(tpTot+ceTot)\n","\n","print(\"Recall: \"+str(R))\n","print(\"Precision: \"+str(P))\n","print(\"Accuracy: \"+str(A))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/FaceMask/DarknetYoloNoDataAug/trainingcompleto/ep080-loss8.454-val_loss8.272.h5 model, anchors, and classes loaded.\n"],"name":"stdout"},{"output_type":"stream","text":[" 99% (1837 of 1838) |################### | Elapsed Time: 0:03:40 ETA:   0:00:00"],"name":"stderr"},{"output_type":"stream","text":["BB true totali: 3061\n","True positive: 2779\n","Classification error: 99\n","False positive: 108\n","False negative: 183\n","Recall: 0.9078732440378962\n","Precision: 0.9625909248354694\n","Accuracy: 0.9656011118832523\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5Aei1ol8RvxJ","colab_type":"code","outputId":"dfe317f9-07b4-41c7-f930-082d3a893aa9","executionInfo":{"status":"ok","timestamp":1588867292215,"user_tz":-120,"elapsed":866141,"user":{"displayName":"ENRICO SAMMARCO","photoUrl":"","userId":"10417850865031477899"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["\n","##################\n","\n","    # yolo v3\n","\n","##################\n","\n","from IPython.display import display\n","from random import randint\n","from PIL import Image, ImageDraw\n","import progressbar\n","\n","\n","model_path = \"/content/drive/My Drive/FaceMask/DarknetYoloDataAug/ep054-loss8.067-val_loss8.021.h5\"\n","txt = open(\"face_mask_test_corrette.txt\",\"r\")\n","label = txt.readlines()\n","label = label[:len(label)-1]\n","txt.close()\n","\n","tpTot = 0\n","ceTot = 0\n","fpTot = 0\n","fnTot = 0\n","totBB = 0\n","\n","arg = {\n","      \"model_path\": model_path,\n","      \"anchors_path\": 'model_data/yolo_anchors.txt', #YOLOV3\n","      \"classes_path\": 'classes.txt',\n","      \"score\" : 0.3,\n","      \"iou\" : 0.45,\n","      \"model_image_size\" : (416, 416), #YOLOV3\n","      \"gpu_num\" : 1,\n","  }\n","detector = YOLO(**arg)\n","\n","bar = progressbar.ProgressBar(max_value=len(label))\n","cont = 0\n","\n","for i in label:\n","  s = i.split(\" \")\n","  true = []\n","  true_classes = []\n","  image = Image.open(s[0])\n","  for j in range(1,len(s)):\n","    punti = s[j].split(\",\")\n","    try:\n","      true.append([int(punti[0]),int(punti[1]),int(punti[2]),int(punti[3]) ])\n","      true_classes.append(int(punti[4]))\n","    except:\n","      print(i)\n","      for punto in punti:\n","        print(punto)\n","  \n","  predicted,pred_classes = detecting_image(detector, image)\n","  tp,ce,fp,fn = compute_performance(predicted, true, pred_classes, true_classes)\n","\n","  tpTot += tp\n","  ceTot += ce\n","  fpTot += fp\n","  fnTot += fn\n","\n","  bar.update(cont)\n","  cont = cont+1\n","  totBB +=len(true)\n","  # print(\"Confronto immagine numero : \"+str(cont)+\" BB presenti:\"+str(len(true))+\" BB trovati: \"+str(len(predicted)))\n","  # print(pred_classes)\n","\n","\n","print(\"BB true totali: \"+str(totBB))\n","print(\"True positive: \"+str(tpTot))\n","print(\"Classification error: \"+str(ceTot))\n","print(\"False positive: \"+str(fpTot))\n","print(\"False negative: \"+str(fnTot))\n","\n","R = tpTot/totBB\n","P = tpTot/(tpTot+fpTot)\n","A = tpTot/(tpTot+ceTot)\n","\n","print(\"Recall: \"+str(R))\n","print(\"Precision: \"+str(P))\n","print(\"Accuracy: \"+str(A))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/FaceMask/DarknetYoloDataAug/ep054-loss8.067-val_loss8.021.h5 model, anchors, and classes loaded.\n"],"name":"stdout"},{"output_type":"stream","text":[" 99% (1837 of 1838) |################### | Elapsed Time: 0:03:40 ETA:   0:00:00"],"name":"stderr"},{"output_type":"stream","text":["BB true totali: 3061\n","True positive: 2802\n","Classification error: 92\n","False positive: 110\n","False negative: 167\n","Recall: 0.9153871283894153\n","Precision: 0.9622252747252747\n","Accuracy: 0.9682100898410505\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yIdd6vHvEfWo","colab_type":"code","outputId":"5f436177-f14d-4f5e-fcc7-df2300d590e5","executionInfo":{"status":"ok","timestamp":1588867416434,"user_tz":-120,"elapsed":985578,"user":{"displayName":"ENRICO SAMMARCO","photoUrl":"","userId":"10417850865031477899"}},"colab":{"base_uri":"https://localhost:8080/","height":224}},"source":["\n","#####################\n","\n","  # tiny yolo v3\n","\n","#####################\n","\n","from IPython.display import display\n","from random import randint\n","from PIL import Image, ImageDraw\n","import progressbar\n","\n","model_path = \"/content/drive/My Drive/FaceMask/TinyYoloDataAug/ep053-loss10.014-val_loss9.798.h5\"\n","txt = open(\"face_mask_test_corrette.txt\",\"r\")\n","label = txt.readlines()\n","label = label[:len(label)-1]\n","txt.close()\n","\n","tpTot = 0\n","ceTot = 0\n","fpTot = 0\n","fnTot = 0\n","totBB = 0\n","\n","arg = {\n","      \"model_path\": model_path,\n","      \"anchors_path\": '/content/model_data/tiny_yolo_anchors.txt', #YOLOV3\n","      \"classes_path\": 'classes.txt',\n","      \"score\" : 0.3,\n","      \"iou\" : 0.45,\n","      \"model_image_size\" : (416, 416), #YOLOV3\n","      \"gpu_num\" : 1,\n","  }\n","detector = YOLO(**arg)\n","\n","bar = progressbar.ProgressBar(max_value=len(label))\n","cont = 0\n","\n","for i in label:\n","  s = i.split(\" \")\n","  true = []\n","  true_classes = []\n","  image = Image.open(s[0])\n","  for j in range(1,len(s)):\n","    punti = s[j].split(\",\")\n","    try:\n","      true.append([int(punti[0]),int(punti[1]),int(punti[2]),int(punti[3]) ])\n","      true_classes.append(int(punti[4]))\n","    except:\n","      print(i)\n","      for punto in punti:\n","        print(punto)\n","  \n","  predicted,pred_classes = detecting_image(detector, image)\n","  tp,ce,fp,fn = compute_performance(predicted, true, pred_classes, true_classes)\n","\n","  tpTot += tp\n","  ceTot += ce\n","  fpTot += fp\n","  fnTot += fn\n","\n","  bar.update(cont)\n","  cont = cont+1\n","  totBB +=len(true)\n","  # print(\"Confronto immagine numero : \"+str(cont)+\" BB presenti:\"+str(len(true))+\" BB trovati: \"+str(len(predicted)))\n","  # print(pred_classes)\n","\n","\n","print(\"BB true totali: \"+str(totBB))\n","print(\"True positive: \"+str(tpTot))\n","print(\"Classification error: \"+str(ceTot))\n","print(\"False positive: \"+str(fpTot))\n","print(\"False negative: \"+str(fnTot))\n","\n","R = tpTot/totBB\n","P = tpTot/(tpTot+fpTot)\n","A = tpTot/(tpTot+ceTot)\n","\n","print(\"Recall: \"+str(R))\n","print(\"Precision: \"+str(P))\n","print(\"Accuracy: \"+str(A))\n","  \n","\n","\n","\n","\n","\n","\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3655: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","/content/drive/My Drive/FaceMask/TinyYoloDataAug/ep053-loss10.014-val_loss9.798.h5 model, anchors, and classes loaded.\n"],"name":"stdout"},{"output_type":"stream","text":[" 99% (1835 of 1838) |################### | Elapsed Time: 0:01:26 ETA:   0:00:00"],"name":"stderr"},{"output_type":"stream","text":["BB true totali: 3061\n","True positive: 2516\n","Classification error: 90\n","False positive: 128\n","False negative: 455\n","Recall: 0.821953609931395\n","Precision: 0.9515885022692889\n","Accuracy: 0.965464313123561\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ltoAcamk3CWe","colab_type":"code","outputId":"7d86235e-91b9-4b30-c697-6b36f03f10cc","executionInfo":{"status":"ok","timestamp":1588867524288,"user_tz":-120,"elapsed":3944,"user":{"displayName":"ENRICO SAMMARCO","photoUrl":"","userId":"10417850865031477899"}},"colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Thu May  7 16:05:20 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   54C    P0    58W / 149W |   6894MiB / 11441MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BvG5TiGa540a","colab_type":"code","outputId":"8da9ee40-d316-4c9c-c95e-750ebfda7503","executionInfo":{"status":"ok","timestamp":1588804563450,"user_tz":-120,"elapsed":3421783,"user":{"displayName":"ENRICO SAMMARCO","photoUrl":"","userId":"10417850865031477899"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","# #####################\n","\n","#   # tiny yolo v3\n","\n","# #####################\n","\n","# from IPython.display import display\n","# from random import randint\n","# from PIL import Image, ImageDraw\n","# import progressbar\n","\n","\n","# def tiny_yolo_test(score,iou):\n","\n","#   model_path = \"/content/drive/My Drive/FaceMask/TinyYoloDataAug/ep053-loss10.014-val_loss9.798.h5\"\n","#   txt = open(\"face_mask_test_corrette.txt\",\"r\")\n","#   label = txt.readlines()\n","#   label = label[:len(label)-1]\n","#   txt.close()\n","\n","#   tpTot = 0\n","#   ceTot = 0\n","#   fpTot = 0\n","#   fnTot = 0\n","#   totBB = 0\n","\n","#   arg = {\n","#         \"model_path\": model_path,\n","#         \"anchors_path\": '/content/model_data/tiny_yolo_anchors.txt', #YOLOV3\n","#         \"classes_path\": 'classes.txt',\n","#         \"score\" : score,\n","#         \"iou\" : iou,\n","#         \"model_image_size\" : (416, 416), #YOLOV3\n","#         \"gpu_num\" : 1,\n","#     }\n","#   detector = YOLO(**arg)\n","\n","#   bar = progressbar.ProgressBar(max_value=len(label))\n","#   cont = 0\n","\n","#   for i in label:\n","#     s = i.split(\" \")\n","#     true = []\n","#     true_classes = []\n","#     image = Image.open(s[0])\n","#     for j in range(1,len(s)):\n","#       punti = s[j].split(\",\")\n","#       try:\n","#         true.append([int(punti[0]),int(punti[1]),int(punti[2]),int(punti[3]) ])\n","#         true_classes.append(int(punti[4]))\n","#       except:\n","#         print(i)\n","#         for punto in punti:\n","#           print(punto)\n","    \n","#     predicted,pred_classes = detecting_image(detector, image)\n","#     tp,ce,fp,fn = compute_performance(predicted, true, pred_classes, true_classes)\n","\n","#     tpTot += tp\n","#     ceTot += ce\n","#     fpTot += fp\n","#     fnTot += fn\n","\n","#     bar.update(cont)\n","#     cont = cont+1\n","#     totBB +=len(true)\n","#     # print(\"Confronto immagine numero : \"+str(cont)+\" BB presenti:\"+str(len(true))+\" BB trovati: \"+str(len(predicted)))\n","#     # print(pred_classes)\n","\n","\n","#   # print(\"BB true totali: \"+str(totBB))\n","#   # print(\"True positive: \"+str(tpTot))\n","#   # print(\"Classification error: \"+str(ceTot))\n","#   # print(\"False positive: \"+str(fpTot))\n","#   # print(\"False negative: \"+str(fnTot))\n","\n","#   R = tpTot/totBB\n","#   P = tpTot/(tpTot+fpTot)\n","#   A = tpTot/(tpTot+ceTot)\n","\n","#   print(\"Performance con score pari a \"+str(score)+\" e IOU pari a \"+str(iou))\n","#   print(\"Recall: \"+str(R))\n","#   print(\"Precision: \"+str(P))\n","#   print(\"Accuracy: \"+str(A))\n","\n","\n","\n","# score = 0.3\n","# iou = 0.2\n","# for i in range(0,6):\n","#   tiny_yolo_test(score,iou+i*0.05)\n","\n","# score = 0.2\n","# iou = 0.45\n","# for i in range(0,4):\n","#   tiny_yolo_test(score+i*0.05,iou)\n","\n","    "],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:167: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:179: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:183: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:507: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3831: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:192: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1797: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:126: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3655: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1940: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n","/content/drive/My Drive/FaceMask/TinyYoloDataAug/ep053-loss10.014-val_loss9.798.h5 model, anchors, and classes loaded.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"stream","text":[" 87% (1607 of 1838) |#################   | Elapsed Time: 0:04:54 ETA:   0:00:42"],"name":"stderr"},{"output_type":"stream","text":["val/test_00000306.jpg \n","\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 99% (1837 of 1838) |################### | Elapsed Time: 0:05:39 ETA:   0:00:00"],"name":"stderr"},{"output_type":"stream","text":["Performance con score pari a 0.3 e IOU pari a 0.2\n","Recall: 0.7750898986596927\n","Precision: 0.9367838798893718\n","Accuracy: 0.9101727447216891\n","/content/drive/My Drive/FaceMask/TinyYoloDataAug/ep053-loss10.014-val_loss9.798.h5 model, anchors, and classes loaded.\n"],"name":"stdout"},{"output_type":"stream","text":[" 87% (1607 of 1838) |#################   | Elapsed Time: 0:04:53 ETA:   0:00:41"],"name":"stderr"},{"output_type":"stream","text":["val/test_00000306.jpg \n","\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 99% (1837 of 1838) |################### | Elapsed Time: 0:05:35 ETA:   0:00:00"],"name":"stderr"},{"output_type":"stream","text":["Performance con score pari a 0.3 e IOU pari a 0.25\n","Recall: 0.7750898986596927\n","Precision: 0.9364139020537124\n","Accuracy: 0.9101727447216891\n","/content/drive/My Drive/FaceMask/TinyYoloDataAug/ep053-loss10.014-val_loss9.798.h5 model, anchors, and classes loaded.\n"],"name":"stdout"},{"output_type":"stream","text":[" 87% (1607 of 1838) |#################   | Elapsed Time: 0:04:54 ETA:   0:00:42"],"name":"stderr"},{"output_type":"stream","text":["val/test_00000306.jpg \n","\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 99% (1837 of 1838) |################### | Elapsed Time: 0:05:36 ETA:   0:00:00"],"name":"stderr"},{"output_type":"stream","text":["Performance con score pari a 0.3 e IOU pari a 0.30000000000000004\n","Recall: 0.7750898986596927\n","Precision: 0.9364139020537124\n","Accuracy: 0.9101727447216891\n","/content/drive/My Drive/FaceMask/TinyYoloDataAug/ep053-loss10.014-val_loss9.798.h5 model, anchors, and classes loaded.\n"],"name":"stdout"},{"output_type":"stream","text":[" 87% (1607 of 1838) |#################   | Elapsed Time: 0:04:52 ETA:   0:00:42"],"name":"stderr"},{"output_type":"stream","text":["val/test_00000306.jpg \n","\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 99% (1837 of 1838) |################### | Elapsed Time: 0:05:34 ETA:   0:00:00"],"name":"stderr"},{"output_type":"stream","text":["Performance con score pari a 0.3 e IOU pari a 0.35000000000000003\n","Recall: 0.7754168028767571\n","Precision: 0.9357001972386588\n","Accuracy: 0.9102072141212586\n","/content/drive/My Drive/FaceMask/TinyYoloDataAug/ep053-loss10.014-val_loss9.798.h5 model, anchors, and classes loaded.\n"],"name":"stdout"},{"output_type":"stream","text":[" 87% (1607 of 1838) |#################   | Elapsed Time: 0:04:54 ETA:   0:00:41"],"name":"stderr"},{"output_type":"stream","text":["val/test_00000306.jpg \n","\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 99% (1837 of 1838) |################### | Elapsed Time: 0:05:36 ETA:   0:00:00"],"name":"stderr"},{"output_type":"stream","text":["Performance con score pari a 0.3 e IOU pari a 0.4\n","Recall: 0.7750898986596927\n","Precision: 0.9345683878596768\n","Accuracy: 0.9101727447216891\n","/content/drive/My Drive/FaceMask/TinyYoloDataAug/ep053-loss10.014-val_loss9.798.h5 model, anchors, and classes loaded.\n"],"name":"stdout"},{"output_type":"stream","text":[" 87% (1607 of 1838) |#################   | Elapsed Time: 0:04:52 ETA:   0:00:42"],"name":"stderr"},{"output_type":"stream","text":["val/test_00000306.jpg \n","\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 99% (1837 of 1838) |################### | Elapsed Time: 0:05:34 ETA:   0:00:00"],"name":"stderr"},{"output_type":"stream","text":["Performance con score pari a 0.3 e IOU pari a 0.45\n","Recall: 0.7750898986596927\n","Precision: 0.9330972058244785\n","Accuracy: 0.9101727447216891\n","/content/drive/My Drive/FaceMask/TinyYoloDataAug/ep053-loss10.014-val_loss9.798.h5 model, anchors, and classes loaded.\n"],"name":"stdout"},{"output_type":"stream","text":[" 87% (1607 of 1838) |#################   | Elapsed Time: 0:04:55 ETA:   0:00:42"],"name":"stderr"},{"output_type":"stream","text":["val/test_00000306.jpg \n","\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 99% (1837 of 1838) |################### | Elapsed Time: 0:05:38 ETA:   0:00:00"],"name":"stderr"},{"output_type":"stream","text":["Performance con score pari a 0.2 e IOU pari a 0.45\n","Recall: 0.7878391631252043\n","Precision: 0.8992537313432836\n","Accuracy: 0.9053343350864012\n","/content/drive/My Drive/FaceMask/TinyYoloDataAug/ep053-loss10.014-val_loss9.798.h5 model, anchors, and classes loaded.\n"],"name":"stdout"},{"output_type":"stream","text":[" 87% (1607 of 1838) |#################   | Elapsed Time: 0:04:57 ETA:   0:00:42"],"name":"stderr"},{"output_type":"stream","text":["val/test_00000306.jpg \n","\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 99% (1837 of 1838) |################### | Elapsed Time: 0:05:40 ETA:   0:00:00"],"name":"stderr"},{"output_type":"stream","text":["Performance con score pari a 0.25 e IOU pari a 0.45\n","Recall: 0.7819548872180451\n","Precision: 0.9178818112049117\n","Accuracy: 0.9074355083459787\n","/content/drive/My Drive/FaceMask/TinyYoloDataAug/ep053-loss10.014-val_loss9.798.h5 model, anchors, and classes loaded.\n"],"name":"stdout"},{"output_type":"stream","text":[" 87% (1607 of 1838) |#################   | Elapsed Time: 0:05:00 ETA:   0:00:42"],"name":"stderr"},{"output_type":"stream","text":["val/test_00000306.jpg \n","\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 99% (1837 of 1838) |################### | Elapsed Time: 0:05:42 ETA:   0:00:00"],"name":"stderr"},{"output_type":"stream","text":["Performance con score pari a 0.30000000000000004 e IOU pari a 0.45\n","Recall: 0.7750898986596927\n","Precision: 0.9330972058244785\n","Accuracy: 0.9101727447216891\n","/content/drive/My Drive/FaceMask/TinyYoloDataAug/ep053-loss10.014-val_loss9.798.h5 model, anchors, and classes loaded.\n"],"name":"stdout"},{"output_type":"stream","text":[" 87% (1607 of 1838) |#################   | Elapsed Time: 0:04:54 ETA:   0:00:42"],"name":"stderr"},{"output_type":"stream","text":["val/test_00000306.jpg \n","\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 99% (1837 of 1838) |################### | Elapsed Time: 0:05:40 ETA:   0:00:00"],"name":"stderr"},{"output_type":"stream","text":["Performance con score pari a 0.35000000000000003 e IOU pari a 0.45\n","Recall: 0.7672441974501472\n","Precision: 0.9475171578522407\n","Accuracy: 0.916796875\n"],"name":"stdout"}]}]}